# ğŸ§  Assistant RAG Local pour la BDNB

Ce projet est un assistant intelligent, basÃ© sur l'architecture **RAG (Retrieval-Augmented Generation)** qui intÃ©rroge la **Base de DonnÃ©es Nationale des BÃ¢timents (BDNB)**.   
Le projet est entiÃ¨rement **exÃ©cutable en local** : aucun appel Ã  une API externe. Il utilise un **modÃ¨le de langage local** (type Mistral) et une base vectorielle **ChromaDB**.


Le choix du stack pour leurs simplicitÃ© d'utilisation, pour des questions de scalabilitÃ© et perfmance une Ã©tude doit Ãªtre menÃ©e; pour le besoin de ce POC, ce stack suffit largement.

---

## ğŸ“ Arborescence du projet

```
.
â”œâ”€â”€ api/                   # Backend FastAPI
â”œâ”€â”€ frontend/              # Interface web React
â”œâ”€â”€ src/                   # Traitement RAG, ingestion, gÃ©nÃ©ration de texte
â”œâ”€â”€ data/                  # Fichiers BDNB transformÃ©s
â”œâ”€â”€ db/                    # dossier base de donnÃ©es vectorielle ChromaDB
â”œâ”€â”€ models_llm/            # ModÃ¨le LLM local (ex: mistral.gguf)
â”œâ”€â”€ notebook/              # Analyses exploratoires (Jupyter)
â”œâ”€â”€ logs/                  # Logs d'exÃ©cution
â”œâ”€â”€ docker-compose.yml     # Orchestration Docker
â”œâ”€â”€ Makefile               # Commandes utiles
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â””â”€â”€ readme.md              # Ce fichier
```

---

## ğŸš€ Lancer le projet

### 1. PrÃ©requis

- Docker & Docker Compose installÃ©s
- Python
- L'utilitaire make installÃ© 


### 1. Intialisation

Lancer la commande `make init` pour initialiser tous les dossiers nÃ©cessaires.  
TÃ©lÃ©charger les poids du modÃ¨le mistral.gguf (ou autre modÃ¨le compatible GGUF) et le stocker dans le dossier `models_llm`.

### 2. Data

Les donnÃ©es sont Ã  tÃ©lÃ©charger [ici](https://www.data.gouv.fr/fr/datasets/r/ad4bb2f6-0f40-46d2-a636-8d2604532f74) ou bien avec la commande `make data`.  
Un Ã©chantillon est tirÃ©, avec lequel on travaillera. Il faut donc lancer la commande `make sample` pour effectuer l'Ã©chantillonage.

Le poids du modÃ¨le Ã  tÃ©lÃ©chager ici, et le placer dans le dossier models_llm.

---

### 2. Lancer l'app (API + Frontend)

```bash
make up
```

- Backend FastAPI : http://localhost:8000
- Frontend React : http://localhost:3000

---

## ğŸ”§ Commandes utiles

```bash
make init            # Initialise tous les dossiers essentiels
make env             # Active l'environnement virtuel et install les dÃ©pendences nÃ©cessaires
make data            # TÃ©lÃ©chager les donnÃ©es brutes
make sample          # Echantillon les donnÃ©es 
make etl             # Lance le pipeline etl, qui charge, transforme les donnÃ©es (features), et les stockes
make up              # Lance docker-compose
make ingest          # Lance l'ingestion RAG (vectorisation des documents)
```

---

## Notebook

Ces notebook contient les codes qui servies du featuring engineering et la reponse aux questions de maniÃ¨res analytiquet en intÃ©geant les base de donnÃ©es avec les requÃªtes.

Vous trouverez 3 notebooks:
- 1. echantillonage.ipynb: echantillons les donnÃ©es Ã  partir du jeu de donnÃ©es brut
- 2. reponse_aux_questions.ipynb: contient les reponses anlytiques aux questions
- 3. preprocessing.ipynb: contient les preprocessing des donnÃ©es. Expliquer les approches, choix, amÃ©lioration possible. Permets de visualiser les resultats intermÃ©daires obtenues et les rÃ©sultats des tables finales.


## ğŸ§© Composants

### ğŸ§  Backend (FastAPI)

- Chargement des embeddings
- Interrogation de ChromaDB
- GÃ©nÃ©ration de rÃ©ponses avec modÃ¨le local (via `llama-cpp-python`)

ğŸ“ Fichiers :
- `api/main.py` : point dâ€™entrÃ©e de lâ€™API
- `src/rag.py` : logique RAG
- `src/ingest_data.py` : ingestion + embeddings
- `src/etl.py` : pipeline elt
- `src/config.py` : contient toutes les configurations nÃ©cessaires
- `src/logger.py` : le logger
- `src/compute_stat.py` et `src/compute_text_batiment.py` : effectue le preprocessing
- `src/compute_stat.py` : sample le jeu de donnÃ©es

---

### ğŸ’» Frontend (React)

Interface minimaliste de type chat pour interroger lâ€™assistant.

ğŸ“ Localisation : `frontend/`

![](./images/Screenshot%20from%202025-04-22%2015-50-37.png)

---

## ğŸ“¦ Technologies utilisÃ©es

| Domaine          | Techno                      |
|------------------|-----------------------------|
| Backend API      | FastAPI                     |
| Embedding & RAG  | ChromaDB + modÃ¨les HF       |
| LLM Local        | Mistral (GGUF)              |
| Vectorisation    | SentenceTransformers (fr)   |
| Frontend         | React + Nginx               |
| Conteneurisation | Docker + Docker Compose     |

---

## ğŸ“ TODO / Roadmap

- [ ] Recherche hybride (mots-clÃ©s + sÃ©mantique)
- [ ] Authentification utilisateur
- [ ] TÃ©lÃ©versement de fichiers
- [ ] GÃ©nÃ©ration de synthÃ¨ses automatiques (par commune / DPE)
- [ ] Fine-tuning du model 
- [ ] Features engineering 
- [ ] DonnÃ©es externe pour enrichier les modÃ¨les (pour le fine-tuning)
- [ ] Evaluation riguoreuse du systÃ¨me 
- [ ] CI/CD (test unitaite/intÃ©gration)
- [ ] Architecture avancÃ©es de RAG
- [ ] Documentation complet de code
- [ ] Fichier sample.py a completer
- [ ] Tester tous les differents scritps

---

## ğŸ“š DonnÃ©es utilisÃ©es

- **Base de DonnÃ©es Nationale des BÃ¢timents (BDNB)**: TÃ©lÃ©charger les donnÃ©es [ici](https://www.data.gouv.fr/fr/datasets/r/ad4bb2f6-0f40-46d2-a636-8d2604532f74)

Un Ã©chantillon de donnÃ©es est utilise pour ce projet (faute de ressources).

## Reponse aux questions
1. 

---

## ğŸ¤ Contributions

Les contributions sont les bienvenues ! Nâ€™hÃ©sitez pas Ã  ouvrir une **issue** ou une **pull request**.
